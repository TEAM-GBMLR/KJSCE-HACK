<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>Chat | ChatApp</title>
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <link rel="stylesheet" href="/css/styles.css" />
  </head>

  <body class="chat">
    <div class="chat__sidebar">
      <h3>People</h3>
      <div id="users"></div>
    </div>

    <div class="chat__main">
      <ol id="messages" class="chat__messages"></ol>

      <div class="chat__footer">
        <form id="message-form">
          <input
            name="message"
            type="text"
            placeholder="Message"
            autofocus
            autocomplete="off"
          />
          <button>Send</button>
        </form>
        <button id="send-location">Send location</button>
      </div>
    </div>

    <script id="message-template" type="text/template">
      <li class="message">
        <div class="message__title">
          <h4>{{from}}</h4>
          <span>{{createdAt}}</span>
        </div>
        <div class="message__body">
          <p>{{text}}</p>
        </div>
      </li>
    </script>

    <script id="location-message-template" type="text/template">
      <li class="message">
        <div class="message__title">
          <h4>{{from}}</h4>
          <span>{{createdAt}}</span>
        </div>
        <div class="message__body">
          <p>
            <a href="{{url}}" target="_blank">My current location</a>
          </p>
        </div>
      </li>
      <video id="video" width="300" height="500" autoplay muted></video>
    </script>

    <script>
            const video = document.getElementById("video");

      Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
        faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
        faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        faceapi.nets.faceExpressionNet.loadFromUri("/models")
      ]).then(startVideo);

      function startVideo() {
        navigator.getUserMedia(
          { video: {} },
          stream => (video.srcObject = stream),
          err => console.error(err)
        );
      }

      video.addEventListener("play", () => {
        const canvas = faceapi.createCanvasFromMedia(video);
        document.body.append(canvas);
        const displaySize = { width: video.width, height: video.height };
        faceapi.matchDimensions(canvas, displaySize);
        setInterval(async () => {
          const detections = await faceapi
            .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks()
            .withFaceExpressions();
          const resizedDetections = faceapi.resizeResults(
            detections,
            displaySize
          );
          canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resizedDetections);
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
          faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
        }, 100);
    </script>
    <script src="/socket.io/socket.io.js"></script>
    <script src="/js/libs/jquery-3.1.0.min.js"></script>
    <script src="/js/libs/moment.js"></script>
    <script src="/js/libs/mustache.js"></script>
    <script src="/js/libs/deparam.js"></script>
    <script src="/js/chat.js"></script>
  </body>
</html>
